{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab05.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5\n",
    "\n",
    "In this lab you will have a chance to try using Pytorch to fit a basic model to a real-world dataset.  Once you have completed this lab you will have:\n",
    "\n",
    "1. Loaded and cleaned a real-world fixed-width data file.\n",
    "2. Fit a linear model using the closed form equations from lecture.\n",
    "3. Constructed and fit a model using Pytorch.\n",
    "\n",
    "**This assignment should be completed and submitted by 11:59 PM on Saturday March 7, 2020.**\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others, please **include their names** in the following cell:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*List collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Used\n",
    "\n",
    "In this lab you will get a chance to use a number of new software libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following torch libraries are used to construct and train models via gradient descent.\n",
    "\n",
    "1. PyTorch (`torch`) is the main pytorch library.\n",
    "2. `torch.nn` is the model design sub-library (`nn` stands for neural network.) \n",
    "3. `torch.nn.functional` contains commonly used functions (e.g., `mse_loss` and `abs_loss`) when building models.\n",
    "4. The `TensorDataset` and `DataLoader` libraries are used to load data efficiently and simplify data sampling.\n",
    "\n",
    "If you are interested in learning more about fitting neural networks and using PyTorch checkout this tutorial: [PyTorch in 60 Minutes](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).  It is worth noting that the basic modeling concepts we teach in this class are also part of this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will have a chance to try using Plotly.  \n",
    "1. `plotly.offline` is the core plotly library and is mainly used for the `py.iplot` syntax. \n",
    "2. `plotly.express` contains very simple `matplotlib` like functions for making standard plots\n",
    "3. `plotly.graph_objects` contains basic plot elements (e.g., `Scatter`, `Lines`, `Bars`, `Contours`) that can be assembled to build plots. \n",
    "4. `cufflinks` is a library that actually modifies the behavior of pandas to allow `df.iplot` mimic the behavior of `df.plot` but instead using `plotly` plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=True, sharing=False, theme='ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A minor note about **Plotly and JupyterLab**.  The latest version of Plotly requires JupyterLab extensions to run in the JupyterLab environment.  Unfortunately, we have not installed those extensions on the DataHub.  You can modify your local environment to work but in general you may need to use the classic notebook environment to use the Plotly plots.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "<br/><br/><br/>\n",
    "\n",
    "## Part 0: Loading the Data\n",
    "\n",
    "For this lab, will use data obtained from the [Earth Systems Research Laboratory (NOAA)](https://www.esrl.noaa.gov/gmd/ccgg/trends/) website. This data was collected at the Mauna Loa Observatory in Hawaii.  We have already downloaded the data into file:\n",
    "\n",
    "```\n",
    "data = \"data/c02.txt\"\n",
    "```\n",
    "\n",
    "Read the documentation attached to the file and examine how it is organized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_head(filename, n=10):\n",
    "    \"\"\"\n",
    "    Print all the line number, a tab character, and the line for all the \n",
    "    lines that begin with the comment_char.\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i in range(n):\n",
    "            print(i, \"\\t\", f.readline().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_head(\"data/co2.txt\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fixed width file format.  The following Pandas code will load the file into a DataFrame.  Take a look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names=[\"Year\", \"Month\", \"Date\", \"Average\", \n",
    "              \"Interpolated\", \"Trend\", \"Num Days\"]\n",
    "\n",
    "data = pd.read_fwf(\"data/co2.txt\", comment=\"#\", names=column_names) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command to plot the data.  You will notice some missing values have been coded as -99.99.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iplot(kind='line', x=\"Date\", y=\"Average\", \n",
    "           xTitle=\"Year\", yTitle=\"CO2 (PPM)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove these datapoints from the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"Average\"] != -99.99] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following visualization should no longer have negative outliers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iplot(kind='scatter', x=\"Date\", y=\"Average\", \n",
    "           xTitle=\"Year\", yTitle=\"CO2 (PPM)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "## Part 1\n",
    "\n",
    "In this part of the assignment you will fit the above data using one dimensional least squares regression introduced in lecture. In particular, given two data vectors $x$ and $y$ of length $n$, we would like to find the slope $m$ and intercept $b$ that minimizes \n",
    "$$\n",
    "L(m, b) = \\sum_{i=1}^{n} \\left(y_i - \\left(m x_i +b\\right) \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Using the implementation of `standard_units` below, implement the remaining three functions. Note that the **correlation** between two vectors $x$ and $y$ of length $n$ is defined as $\\frac{1}{n} \\sum_{i=1}^{n} x_i y_i$.  You will find the answer to these questions in lecture but try to answer them yourself first.  Also **don't use for loops**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are giving you this function because we have written it in a way\n",
    "# that will also work with Pytorch vectors. (Do you see why?)\n",
    "def standard_units(x):\n",
    "    \"\"\"Return the 1d vector in standard unit form.\"\"\"\n",
    "    return (x - x.mean()) / x.std() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y):\n",
    "    \"\"\"Compute the correlation between two 1d vectors.\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(x, y):\n",
    "    \"\"\"Compute the slope of the least squares regression line.\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercept(x, y):\n",
    "    \"\"\"Compute the intercept of the least squares regression line.\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented things correctly, the following will print the slope and intercept of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = slope(data[\"Date\"], data[\"Average\"])\n",
    "b = intercept(data[\"Date\"], data[\"Average\"])\n",
    "\n",
    "# Make a prediction\n",
    "yhat = m * data['Date'] + b\n",
    "residual = data['Average'] - yhat\n",
    "print(\"Slope:\", m)\n",
    "print(\"Intercept:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the interecept has a large negative value.  This will be an issue in later steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Model\n",
    "\n",
    "Run the following to visualize the line of best fit and the corresponding residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True) \n",
    "\n",
    "# Add the Data\n",
    "fig.add_trace(go.Scatter(x=data[\"Date\"], y=data[\"Average\"], name=\"Data\",\n",
    "                         mode=\"markers+lines\", \n",
    "                         marker=go.scatter.Marker(size=2.5),\n",
    "                         line=go.scatter.Line(width=1)), row=1, col=1)\n",
    "# Add the line of best fit.\n",
    "fig.add_trace(go.Scatter(x=data[\"Date\"], y=yhat, name='Best Fit Line' ),\n",
    "              row=1, col=1)\n",
    "\n",
    "# Plot the Residual \n",
    "fig.add_trace(go.Scatter(x=data[\"Date\"], y=residual, name='Residuals' ),\n",
    "              row=2, col=1)\n",
    "\n",
    "# Axis Labels\n",
    "fig.update_xaxes(title_text=\"Year\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Y\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Residual\", row=2, col=1)\n",
    "fig.update_layout(height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice any pattern in the residual?  Is there any structure left in the relationship between $y$ and $x$?  The next part of this problem will try to address this structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "## Part 2\n",
    "\n",
    "Notice in the above plot that there is some parabolic curvature in the residual.  In this part of the assignment, we will improve our model by adding a quadratic component using PyTorch. Adding a quadratic component to the model makes it difficult but not impossible to find an analytic solution to the regression problem.  In future lectures we will see that there is indeed an analytic solution to this linear model.  However, here we will resort to using numerical iterative methods and in particular SGD to find the optimal model.  PyTorch comes in handy here because given the model and the loss function, PyTorch can compute the gradient that is needed for SGD.\n",
    "\n",
    "\n",
    "We first convert the data into Pytorch tensors in the following lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(data[['Date']].to_numpy())\n",
    "y = torch.from_numpy(data[['Average']].to_numpy())\n",
    "print(\"Shape of x:\", x.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2\n",
    "\n",
    "Given that the above data has some parabolic curvature, we would like to try and fit a model of the form:\n",
    "\n",
    "$$\n",
    "y = w_0 + w_1 x + w_2 x^2\n",
    "$$\n",
    "\n",
    "Finish implementing the `forward` function for our model in PyTorch below:\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # We initialized three weights [0,0,0] for our model.\n",
    "        self.w = nn.Parameter(torch.zeros(3,1))\n",
    "    def forward(self, x):\n",
    "        w = self.w # you can access w[0], w[1], and w[2]\n",
    "        y = ...\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Question 3\n",
    "\n",
    "Fill in the implementation for the mean squared loss function below. Please make sure that your implementation is compatible with PyTorch. Considering using `torch.mean`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y, yhat):\n",
    "    \"\"\"Compute the mean squared loss between the tensors y and yhat\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the mean squared error of our initial model with parameters initialized as all zeros on our dataset with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = QuadraticModel()\n",
    "mse_loss(y, m(x)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Question 4\n",
    "\n",
    "Now that you have implemented the model and the loss, please implement the following SGD function.  Note that the solution is provided in lecture but try to solve the problem yourself first.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(model, loss_fn, dataset, lr=lambda t: 1./(1.+t), nepochs=10, batch_size=10):\n",
    "    \"\"\"\n",
    "    Run SGD on the provdied model, loss function, and pytorch dataset.\n",
    "    \"\"\"\n",
    "    loader = ...\n",
    "    for t in range(nepochs):\n",
    "        for (x, y) in loader:\n",
    "            # Steps:\n",
    "            # 1. Compute the loss\n",
    "            # 2. Run backpropagation on the loss.\n",
    "            # 3. With torch.no_grad():\n",
    "            #     a) for each parameter p in model.parameters()\n",
    "            #         i. subtract the learning rate lr(t) times gradient (p.grad)\n",
    "            #.    b) Zero the gradient after you used it. (model.zero_grad())\n",
    "            ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In contrast to lecture here we have modified the learning rate to be a function of the epoch rather than a constant.  This allows you to experiment with different learning rate schedules.  You might consider:\n",
    "\n",
    "```\n",
    "lr = lambda t: 0.1\n",
    "lr = lambda t: 1.0/np.sqrt(1.0 + t)\n",
    "lr = lambda t: 1.0/(1.0 + t)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 5\n",
    "\n",
    "Let's test your implementation of PyTorch model, loss, and SGD.  Here we will create a tiny toy dataset from a toy model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_model = QuadraticModel()\n",
    "toy_model.w.data = torch.tensor([0.5, -0.2, 1.])\n",
    "toy_x = torch.linspace(-1,1,50)\n",
    "toy_y = toy_model(toy_x).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=toy_x.numpy(), y=toy_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Try running SGD on this toy data by picking some reasonable values for the learning rate `lr`, the `batch_size`, and the number of epochs `nepochs`.  \n",
    "\n",
    "Suggestions: \n",
    "1. Keep the batch size small relative to the dataset size.\n",
    "2. Try the default learning rate function and perhaps a constant function `lr = lambda t: 0.1`.  You might also try `lr = lambda t: 1./ np.sqrt(t + 1)`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = ...\n",
    "nepochs = ...\n",
    "lr = ...\n",
    "\n",
    "model = QuadraticModel() \n",
    "dataset = TensorDataset(toy_x, toy_y)\n",
    "sgd(model, mse_loss, dataset, lr=lr, batch_size=batch_size, nepochs=nepochs)\n",
    "\n",
    "yhat = model(toy_x).detach()\n",
    "print(\"Loss:\", mse_loss(toy_y, yhat).item())\n",
    "print(\"Weights:\", model.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did we estimate the model correctly?  Let's visualize the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=toy_x.numpy(), y=toy_y.numpy())\n",
    "# Add the line of best fit.\n",
    "fig.add_trace(go.Scatter(x=toy_x.numpy(), y=yhat.numpy(), name='Best Fit Line' ))\n",
    "# Axis Labels\n",
    "fig.update_xaxes(title_text=\"X\")\n",
    "fig.update_yaxes(title_text=\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 6\n",
    "\n",
    "Try running SGD for a few epochs on our CO2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100 \n",
    "nepochs = 1\n",
    "lr = lambda t: 1./ np.sqrt(t + 1) \n",
    "\n",
    "model = QuadraticModel() \n",
    "dataset = TensorDataset(x, y)\n",
    "sgd(model, mse_loss, dataset, lr=lr, batch_size=batch_size, nepochs=nepochs)\n",
    "\n",
    "yhat = model(x).detach()\n",
    "print(\"Loss:\", mse_loss(y, yhat).item())\n",
    "print(\"Weights:\", model.w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output above is a lot of `nan` you are not alone.  What went wrong?  Our initial model parameters $[0, 0, 0]$ are really far from optimum.  Recall from before that the intercept of the line was a very large negative number.  There are a few solutions. \n",
    "\n",
    "1. We could try to adjust our learning rate and using clipping to to prevent diverging gradients.  \n",
    "2. We could standardize our data so there are no large values.  (We will do this one). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use the standardize function from before to transform the data into standard units.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = ...\n",
    "ys = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q6\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 7\n",
    "\n",
    "Try running the algorithm once more on our standardized data by picking some reasonable values for the learning rate `lr`, the `batch_size`, and the number of epochs `nepochs`.  \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = ...\n",
    "nepochs = ...\n",
    "lr = ...\n",
    "dataset = ...\n",
    "\n",
    "model = QuadraticModel() \n",
    "sgd(model, mse_loss, dataset, lr=lr, batch_size=batch_size, nepochs=nepochs)\n",
    "\n",
    "yhat = model(xs).detach() \n",
    "residual = (ys - yhat).detach().flatten()\n",
    "print(\"Loss:\", mse_loss(ys, yhat).item())\n",
    "print(\"Weights:\", model.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q7\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=xs.flatten(), y=ys.flatten(), name=\"Data\",\n",
    "                         mode=\"markers+lines\", \n",
    "                         marker=go.scatter.Marker(size=2.5),\n",
    "                         line=go.scatter.Line(width=1)), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=xs.flatten(), y=yhat.detach().flatten(), \n",
    "                         name='Best Quadratic' ),\n",
    "              row=1, col=1)\n",
    "# Bottom Plot\n",
    "fig.add_trace(go.Scatter(x=xs.flatten(), y=residual, name='Residuals'),\n",
    "              row=2, col=1)\n",
    "# Axis Labels\n",
    "fig.update_xaxes(title_text=\"Year\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Y\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Residual\", row=2, col=1)\n",
    "fig.update_layout(height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Extra: fit the data using an even more complicated model!\n",
    "\n",
    "What if we were really committed to fitting the data? Consider the following model  \n",
    "\n",
    "$$\n",
    "\\text{SinModel}_{w, \\phi}(x) = \\sum_{k=1}^{p} w_k sin(2\\pi k x + \\phi_k)\n",
    "$$\n",
    "\n",
    "where $p$ is a user-defined constant which determines the number of sines in the model and the parameters we aim to learn are $\\{ w_k, \\phi_k \\}_{k=1}^p$. \n",
    "\n",
    "\n",
    "We can combine this model with our quadratic model to make a new `QuadSinModel` (see below):\n",
    "\n",
    "$$\n",
    "\\text{QuadSinModel}_{u, w, \\phi}(x) = \\text{QuadraticModel}_{u}(x) + \\text{SinModel}_{w, \\phi}(x)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Try changing the number of sine functions `p` and observe how it affects the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinBasis(nn.Module):\n",
    "    def __init__(self, p=1):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.randn(p,1).double())\n",
    "        self.phase = nn.Parameter(torch.randn(p,1).double())\n",
    "        self.freq = torch.tensor(2*np.pi *(1. + np.arange(p))).unsqueeze(0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        w = self.w\n",
    "        phase = self.phase\n",
    "        freq = self.freq\n",
    "        # Explaining the following calculation:\n",
    "        #   0. The @ operator is matrix multiplication. \n",
    "        #   1. x is a tall (n,1) matrix and freq.T is a row (1,p)-matrix\n",
    "        #   2. x @ freq => is all combinations of x at each frequency (n, p)-matrix\n",
    "        #   3. phase.T is \"broadcast\" (and added) to each row of the (n, p)-matrix\n",
    "        #   4. torch.sin(x @ freq + phase.T) is an (n, p)-matrix that when multiplied by w\n",
    "        #      produces an (n, 1) prediction matrix\n",
    "        predictions = torch.sin(x @ freq + phase.T) @ w\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model combines our earlier two models to produce a new \"better\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadSinModel(nn.Module):\n",
    "    def __init__(self, p=50):\n",
    "        super().__init__()\n",
    "        self.quad = QuadraticModel()\n",
    "        self.sinbasis = SinBasis(p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        quad_model = self.quad\n",
    "        sin_model = self.sinbasis\n",
    "        predictions = quad_model(x) + sin_model(x) \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains this new better model (and may take a few seconds to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of Sine functions to use\n",
    "p = 200\n",
    "batch_size = 100 \n",
    "nepochs = 200 \n",
    "lr = lambda t: 1./ (1.0 + t) \n",
    "dataset = TensorDataset(xs, ys) \n",
    "\n",
    "crazy_model = QuadSinModel(p)\n",
    "sgd(crazy_model, mse_loss, dataset, lr=lr, batch_size=batch_size, nepochs=nepochs)\n",
    "\n",
    "yhat = crazy_model(xs).detach() \n",
    "residual = (ys - yhat).detach().flatten()\n",
    "print(\"Loss:\", mse_loss(ys, yhat).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=xs.flatten(), y=ys.flatten(), name=\"Data\",\n",
    "                         mode=\"markers+lines\", \n",
    "                         marker=go.scatter.Marker(size=2.5),\n",
    "                         line=go.scatter.Line(width=1)), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=xs.flatten(), y=yhat.detach().flatten(), \n",
    "                         name='Crazy Model' ),\n",
    "              row=1, col=1)\n",
    "# Bottom Plot\n",
    "\n",
    "fig.add_trace(go.Scatter(x=xs.flatten(), y=residual, name='Residuals'),\n",
    "              row=2, col=1)\n",
    "# Axis Labels\n",
    "fig.update_xaxes(title_text=\"Year (Standardized)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Y\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Residual\", row=2, col=1)\n",
    "fig.update_layout(height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to share your clever solutions or improvements to this last step in the Piazza thread [@888](https://piazza.com/class/k4zyqkjkyt33a2?cid=888)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
